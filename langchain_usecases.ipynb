{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7352b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162290ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d401670",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9dd09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8190ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing OpenAI connection\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882e6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries for respective LLM\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0b2df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Pomeranian is a breed of dog, typically small in size with a fluffy coat and a fox-like face. They are known for their playful and friendly nature.\n"
     ]
    }
   ],
   "source": [
    "#Using Langchain to answer questions over documents (CSVs, PDFs)\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "question = \"Which is the pomeranian?\"\n",
    "\n",
    "#Does not give desired answer\n",
    "output = llm.invoke(question)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed58ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple use case of external documents. Ex. Convert PDF to text -> split text -> embed text -> search against text\n",
    "\n",
    "context = \"\"\"\n",
    "\n",
    "Max is a cockapoo.\n",
    "Misa is a pomeranian.\n",
    "Leo is a mixed pomeranian.\n",
    "Ollie is a golden doodle.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c90c6ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Misa and Leo are both pomeranians.\n"
     ]
    }
   ],
   "source": [
    "#Instead of appending like below, we can use langchain's \"load_qa_chain\"\n",
    "\n",
    "output = llm.invoke(context + question)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae2ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Langchain to query tabular data and answer questions related to them\n",
    "\n",
    "from langchain import SQLDatabase\n",
    "from langchain_experimental.sql.base import SQLDatabaseChain\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c7b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create connection to database with OpenAI\n",
    "\n",
    "sqlite_db_path = \"langchain.db\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0) #Temperature is the randomness of each response/output; where 0.7 is more random and 0.2 is less random\n",
    "#In this case we are not looking for something dynamic\n",
    "\n",
    "db_chain = SQLDatabaseChain.from_llm(llm=llm, db=db, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0bb06a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_question = \"Which is the most expensive item?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9f3956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "Which is the most expensive item?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT \"ITEM_NAME\", \"ITEM_PRICE\" FROM item ORDER BY \"ITEM_PRICE\" DESC LIMIT 1\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('Xbox', 499.99)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mXbox\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "db_answer = db_chain.invoke(db_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e763f92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Which is the most expensive item?', 'result': 'Xbox'}\n"
     ]
    }
   ],
   "source": [
    "print(db_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11dbd13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Langchain to interact with APIs\n",
    "\n",
    "from langchain.chains import APIChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "793f16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"https://api.jikan.moe/v4/anime?q=naruto&sfw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc73c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_chain = APIChain.from_llm_and_api_docs(llm, endpoint ,verbose=True, limit_to_domains=[\"https://api.jikan.moe/\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ff280f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m https://api.jikan.moe/v4/anime?q=naruto&sfw&order_by=score&sort=desc&limit=1\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{\"pagination\":{\"last_visible_page\":30,\"has_next_page\":true,\"current_page\":1,\"items\":{\"count\":1,\"total\":30,\"per_page\":1}},\"data\":[{\"mal_id\":53236,\"url\":\"https:\\/\\/myanimelist.net\\/anime\\/53236\\/Road_of_Naruto\",\"images\":{\"jpg\":{\"image_url\":\"https:\\/\\/cdn.myanimelist.net\\/images\\/anime\\/1731\\/128787.jpg\",\"small_image_url\":\"https:\\/\\/cdn.myanimelist.net\\/images\\/anime\\/1731\\/128787t.jpg\",\"large_image_url\":\"https:\\/\\/cdn.myanimelist.net\\/images\\/anime\\/1731\\/128787l.jpg\"},\"webp\":{\"image_url\":\"https:\\/\\/cdn.myanimelist.net\\/images\\/anime\\/1731\\/128787.webp\",\"small_image_url\":\"https:\\/\\/cdn.myanimelist.net\\/images\\/anime\\/1731\\/128787t.webp\",\"large_image_url\":\"https:\\/\\/cdn.myanimelist.net\\/images\\/anime\\/1731\\/128787l.webp\"}},\"trailer\":{\"youtube_id\":null,\"url\":null,\"embed_url\":null,\"images\":{\"image_url\":null,\"small_image_url\":null,\"medium_image_url\":null,\"large_image_url\":null,\"maximum_image_url\":null}},\"approved\":true,\"titles\":[{\"type\":\"Default\",\"title\":\"Road of Naruto\"},{\"type\":\"Synonym\",\"title\":\"Naruto 20th Anniversary PV\"},{\"type\":\"Japanese\",\"title\":\"ROAD OF NARUTO\"},{\"type\":\"English\",\"title\":\"Road of Naruto\"}],\"title\":\"Road of Naruto\",\"title_english\":\"Road of Naruto\",\"title_japanese\":\"ROAD OF NARUTO\",\"title_synonyms\":[\"Naruto 20th Anniversary PV\"],\"type\":\"PV\",\"source\":\"Manga\",\"episodes\":1,\"status\":\"Finished Airing\",\"airing\":false,\"aired\":{\"from\":\"2022-10-03T00:00:00+00:00\",\"to\":null,\"prop\":{\"from\":{\"day\":3,\"month\":10,\"year\":2022},\"to\":{\"day\":null,\"month\":null,\"year\":null}},\"string\":\"Oct 3, 2022\"},\"duration\":\"9 min\",\"rating\":\"PG-13 - Teens 13 or older\",\"score\":8.44,\"scored_by\":19733,\"rank\":null,\"popularity\":3814,\"members\":33095,\"favorites\":113,\"synopsis\":\"In celebration of 20 years of Naruto, Studio Pierrot posted an anniversary PV on their YouTube channel. The PV is a compilation of newly reworked scenes from Naruto containing new animation.\",\"background\":null,\"season\":null,\"year\":null,\"broadcast\":{\"day\":null,\"time\":null,\"timezone\":null,\"string\":null},\"producers\":[],\"licensors\":[],\"studios\":[{\"mal_id\":1,\"type\":\"anime\",\"name\":\"Pierrot\",\"url\":\"https:\\/\\/myanimelist.net\\/anime\\/producer\\/1\\/Pierrot\"}],\"genres\":[{\"mal_id\":1,\"type\":\"anime\",\"name\":\"Action\",\"url\":\"https:\\/\\/myanimelist.net\\/anime\\/genre\\/1\\/Action\"},{\"mal_id\":10,\"type\":\"anime\",\"name\":\"Fantasy\",\"url\":\"https:\\/\\/myanimelist.net\\/anime\\/genre\\/10\\/Fantasy\"}],\"explicit_genres\":[],\"themes\":[{\"mal_id\":17,\"type\":\"anime\",\"name\":\"Martial Arts\",\"url\":\"https:\\/\\/myanimelist.net\\/anime\\/genre\\/17\\/Martial_Arts\"}],\"demographics\":[{\"mal_id\":27,\"type\":\"anime\",\"name\":\"Shounen\",\"url\":\"https:\\/\\/myanimelist.net\\/anime\\/genre\\/27\\/Shounen\"}]}]}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = api_chain.invoke(\"What is the highest rated Naruto film?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1f02944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is the highest rated Naruto film?', 'output': ' The highest rated Naruto film is \"Road of Naruto\", a 9-minute PV celebrating the 20th anniversary of Naruto. It has a score of 8.44 and is rated PG-13. The PV contains new animation and scenes from the original Naruto series. It was released on October 3, 2022.'}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1417f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Langchain to extract key data from text and make it more readable\n",
    "\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c636d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2582dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define instructions on what you want extracted\n",
    "instructions = \"\"\"\n",
    "\n",
    "Given a text which contains human names, extract the human names of those who have a dog.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "444dc617",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jeff has a cockapoo, Bob has a fish and John has a wolf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f167991",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = instructions + text\n",
    "output = chat_model.invoke([HumanMessage(content=prompt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28c3ece5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff, John\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3be417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Kor (thin wrapper on LLMs for providing structured data response)\n",
    "%pip install kor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64782f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text, Number\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15b7e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide your schema (We can also use different models)\n",
    "schema = Object(\n",
    "    id=\"person\",\n",
    "    description=\"personal information\",\n",
    "    examples=[\n",
    "        (\"John Doe and Jane Doe are siblings\", [{\"first_name\": \"John\", \"last_name\": \"Doe\"}, {\"first_name\": \"Jane\", \"last_name\": \"Doe\"}])\n",
    "    ],\n",
    "         attributes=[\n",
    "             Text(\n",
    "                 id=\"first_name\",\n",
    "                 description=\"First name of a person\"\n",
    "             ),\n",
    "             Text(\n",
    "                 id=\"last_name\",\n",
    "                 description=\"Last name of a person\"\n",
    "             )\n",
    "         ],\n",
    "         many=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7a5e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"John Doe has a sister named Jane. Their mom is named Lisa and she has a friend named Jeff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6ec960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "extraction_chain = create_extraction_chain(llm, schema, encoder_or_encoder_class=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aff6bf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your goal is to extract structured information from the user's input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.\n",
      "\n",
      "```TypeScript\n",
      "\n",
      "person: Array<{ // personal information\n",
      " first_name: string // First name of a person\n",
      " last_name: string // Last name of a person\n",
      "}>\n",
      "```\n",
      "\n",
      "\n",
      "Please output the extracted information in CSV format in Excel dialect. Please use a | as the delimiter. \n",
      " Do NOT add any clarifying information. Output MUST follow the schema above. Do NOT add any additional columns that do not appear in the schema.\n",
      "\n",
      "\n",
      "\n",
      "Input: John Doe and Jane Doe are siblings\n",
      "Output: first_name|last_name\n",
      "John|Doe\n",
      "Jane|Doe\n",
      "\n",
      "Input: [user input]\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "#The prompt that is fed to ChatGPT behind the scenes\n",
    "print(extraction_chain.prompt.format_prompt(text=\"[user input]\").to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6e03651",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction = extraction_chain.invoke(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67ce4de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'person': [{'first_name': 'John', 'last_name': 'Doe'}, {'first_name': 'Jane', 'last_name': 'Doe'}]}\n"
     ]
    }
   ],
   "source": [
    "print(extraction[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16b8f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pydantic Model\n",
    "from typing import Optional\n",
    "\n",
    "from kor import from_pydantic\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    first_name: Optional[str] = Field(\n",
    "        default=None, description=\"First name of the person\"\n",
    "    )\n",
    "    last_name: Optional[str] = Field(\n",
    "        default=None, description=\"Last name of the person\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28f9090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema, validator = from_pydantic(Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "454582b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = create_extraction_chain(\n",
    "    llm, schema, encoder_or_encoder_class=\"csv\", validator=validator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1dc1037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction = extraction_chain.run(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64a5492f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'person': [{'first_name': 'John', 'last_name': 'Doe'}]}\n"
     ]
    }
   ],
   "source": [
    "print(extraction[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7577cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Popular math archive\n",
    "%pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2dcfaa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Langchains Agents (Langchain provides a variety of agents, we can also create our own)\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import load_tools, initialize_agent, AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95851bdf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "tools = load_tools(\n",
    "    [\"arxiv\"]\n",
    ")\n",
    "\n",
    "agent_chain = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d9cbcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ask question about the text\n",
    "text = \"what is the 2402.08284 paper about?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f63b41c1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should search for the paper on arxiv to find out its content.\n",
      "Action: arxiv\n",
      "Action Input: 2402.08284\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPublished: 2024-02-13\n",
      "Title: A Logical Approach to Criminal Case Investigation\n",
      "Authors: Takanori Ugai, Yusuke Koyanagi, Fumihito Nishino\n",
      "Summary: XAI (eXplanable AI) techniques that have the property of explaining the\n",
      "reasons for their conclusions, i.e. explainability or interpretability, are\n",
      "attracting attention. XAI is expected to be used in the development of forensic\n",
      "science and the justice system. In today's forensic and criminal investigation\n",
      "environment, experts face many challenges due to large amounts of data, small\n",
      "pieces of evidence in a chaotic and complex environment, traditional laboratory\n",
      "structures and sometimes inadequate knowledge. All these can lead to failed\n",
      "investigations and miscarriages of justice. In this paper, we describe the\n",
      "application of one logical approach to crime scene investigation. The subject\n",
      "of the application is ``The Adventure of the Speckled Band'' from the Sherlock\n",
      "Holmes short stories. The applied data is the knowledge graph created for the\n",
      "Knowledge Graph Reasoning Challenge. We tried to find the murderer by inferring\n",
      "each person with the motive, opportunity, and method. We created an ontology of\n",
      "motives and methods of murder from dictionaries and dictionaries, added it to\n",
      "the knowledge graph of ``The Adventure of the Speckled Band'', and applied\n",
      "scripts to determine motives, opportunities, and methods.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe paper is about applying a logical approach to criminal case investigation using XAI techniques.\n",
      "Final Answer: The 2402.08284 paper is about using XAI techniques for criminal case investigation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent_response = agent_chain.run(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e28a3383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2402.08284 paper is about using XAI techniques for criminal case investigation.\n"
     ]
    }
   ],
   "source": [
    "print(agent_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "381b2208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Langchain to understand code\n",
    "\n",
    "from langchain.text_splitter import Language\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "323de75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(disallowed_special=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6e20b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b39b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clone repository you want explained\n",
    "!git clone https://github.com/Taisunnn/riskthinking-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "692ac57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"riskthinking-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc2ba838",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericLoader.from_filesystem(\n",
    "    root_dir,\n",
    "    glob=\"**/*\",\n",
    "    suffixes=[\".py\"],\n",
    "    exclude=[\"**/non-utf8-encoding.py\"],\n",
    "    parser=LanguageParser(parser_threshold=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f00efeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0853dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=2000, chunk_overlap=200\n",
    ")\n",
    "texts = python_splitter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98334eec",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "db = Chroma.from_documents(texts, OpenAIEmbeddings(disallowed_special=()))\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents, embeddings).as_retriever()\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",  # Also test \"similarity\"\n",
    "    search_kwargs={\"k\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65d713fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69f44257",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is this repository about?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1910e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = {\n",
    "\"dialect\": \"Python\",\n",
    "\"question\": query,\n",
    "\"chat_history\": [], # or provide an actual chat history\n",
    "\"agent_scratchpad\": {} # or provide an actual agent scratchpad\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4dd0760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 15, updating n_results = 15\n"
     ]
    }
   ],
   "source": [
    "response = qa.run(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dee1b951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This repository is related to a Stock Market Pipeline project. The pipeline involves downloading stock market data from Kaggle, transforming the data, and training a machine learning model on the transformed data. The project also includes a FastAPI implementation for making predictions using the trained model. The repository contains scripts for downloading data, transforming data, training the model, and serving the model via FastAPI endpoints.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
